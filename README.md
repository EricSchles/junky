junky
=====

### Bad Data == Bad Analysis
Junky is a WiP started at PyGotham 2014 intended to one day become a tool to quickly identify potential problems in the distribution and normalization of datasets.

### Dependencies
- Pandas, numpy, etc


### Tasks
_Dataset Size_
  - How many records? How much space do we have to examine subgroups?
  
_Normalization of Variables_
  - In columns with string types does the data need to be cleaned to normalize categories?
  
_Likelihood of Missing Data_
  - Percentage of Null values for each column
  - Rows with missing columns

_Normal Distributions_
  - Z-scores, T-tests, F-tests, heteroskedasticity, and box-jenkins test 
  - Max, Min, Median, Mode, Mean
